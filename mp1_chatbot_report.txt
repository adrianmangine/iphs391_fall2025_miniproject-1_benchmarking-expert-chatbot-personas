Section 1: Executive Summary
        I chose to create the chatbot under the persona of Professor Alden Shores, a molecular neuroscience researcher, nature peer-reviewer, and gentle but firm professor. The chatbot turned out to be amazing. It provides very informative but concise answers to the given question. It covers many bases: research techniques, cellular/molecular/network-level understanding of tough concepts, experimental considerations, receptivity, and proper literature review/citations. I was very impressed with the breadth and depth of the answers provided, especially across multiple different fields, techniques, and approaches to molecular neuroscience. The chatbot also included a follow up question to ensure that I understood the material. This was an impressive and unexpected addition, and was a benefit to the persona. Lastly, I sent the link to my parents and friends and they prompted the chatbot to “answer like you’re speaking to someone who knows nothing about neuroscience,” and it was extremely effective in doing so. This was a nice and unexpected experiment, as I only prompted complex and technical questions. 
        Rubric score: 
Persona Consistency & Voice → 23/25
Warm, rigorous, Socratic tone present in nearly every turn.
Technical Accuracy & Depth → 24/25
Correct mechanisms and molecular detail (NRXN/NLGN, ephrin signaling, LSD pathways).
Teaching Priorities & Rigor → 17/20
Strong on controls and operational definitions, but could expand more on preregistration/stats.
Evidence-First → 13/15
Frequently flags limitations, but not many numerical effect sizes.
Engagement & Challenge → 14/15
Nearly every answer ends with a probing question or challenge.
Weighted Score:
Persona Consistency: 23/25 × 0.25 = 23
Technical Accuracy: 24/25 × 0.25 = 24
Teaching Priorities: 17/20 × 0.20 = 17
Evidence-First: 13/15 × 0.15 = 13
Engagement: 14/15 × 0.15 = 14
Final Score = 91/100 → Excellent Persona Realization
        I think this is an accurate score for the chatbot. However, I would argue that the rubric failed to credit the chatbot in the “teaching priorities and rigor” section. I am not fully convinced that expanding more on preregistration/stats is as important as the rubric defines it to be. If I were to grade the chatbot, It would get a higher grade - an additional three points in the aforementioned category. The chatbot, after every interaction, would prompt a knowledge-check question to ensure that the user understood the material. I think that is worthy enough to credit the bot with a higher score in teaching priorities and rigor. On all of the other fronts, I agree with the score and the sentiment behind it. 


Section 2: Persona Design Strategy
        I was looking to emulate a calm and collected, but firm and knowledgeable molecular neuroscience Professor. I have spent a considerable amount of time in my coursework studying molecular neuroscience, specifically synaptic adhesion molecules and synaptic plasticity, and so I only thought it would be fitting to try and emulate a professor. I wanted the persona to reflect both the patience of a teacher who can guide students step by step, and the rigor of a researcher who demands clarity and evidence. In choosing this target, I’m also drawing on the kinds of conversations I’ve had with my own professor: curious and aspirational, but empirical and realistic . The goal was to create a voice that balances approachability with authority, so the chatbot feels like a true mentor while still holding a high bar for precision and depth.
        In terms of prompt engineering, it was admittedly minimal. I had one goal and one goal only, and my first iteration of the prompt was the one that I resonated with and felt was accurate. I do however understand that further iterations could have been more informational, and that is something I would redo in hindsight. I prompted ChatGPT 5 to create me a chatbot that was a professor, and had the traits that I targeted in the aforementioned paragraph. 
        I think the chatbot has a great persona, and one that is keenly accurate to its goal. In the system prompt persona, directions like: “Review ethos (peer-reviewer mode when asked to “review” or “critique”) Assess novelty, methods rigor, statistics, claims vs. evidence, reproducibility (reagents, code, data), and ethics. Provide actionable revision bullets (major vs. minor), including specific experiments or analyses to shore up claims.”, and “Prefer short, structured answers with numbered steps, quick definitions, and optional references/suggested readings when useful” were some of the key instructions that I think shaped the chatbot into a realistic mentor and professor. What makes the persona complex is that it isn’t just parroting back facts, it can approach questions from multiple angles: as a teacher breaking down concepts, as a lab PI stressing controls and reproducibility, or as a peer reviewer providing structured critique. It also engages in thought-provoking interactions by asking clarifying questions at the end of an exchange, which forces the user to refine their own reasoning and keeps the conversation dynamic. These layers of role-shifting and interaction go beyond simple role-play and give the chatbot the depth and adaptability of an actual professor. Here, it encourages augmenting vs. automation. 
Section 3: Iterative Development Process
        In my initial attempts at building the persona, I wrote a fairly straightforward prompt that established the basics: the chatbot would be a calm, collected, but firm molecular neuroscience professor. Interestingly, the first draft happened to capture much of what I wanted. It naturally leaned into questioning the user, structured explanations, structure theoretical lectures with, all without me explicitly planning all of it. This made the chatbot feel more like a true mentor than I expected on the first try, and then I got embedded in all of the chats and tried to explore all of its functions. While this was a fortunate outcome, it also meant that I didn’t iterate as much as I could have, since I felt satisfied early on with how well the persona worked.
        To address my refinement cycles and meta-prompting insights, there was honestly nothing (in my opinion) to actually refine. I tested the chatbot on all of the strategies mentioned earlier in this summary (planning classes, question answering/prompting, research ethics and techniques, etc.,) and it was surprisingly good at everything. All of the information was thorough, concise, and displayed knowledge of many aspects of scientific inquiry. In turn, this led to limited iterations of the chatbot. While this was convenient, it also meant I didn’t push the persona to its limits. I recognize that iteration isn’t only about fixing problems, but also about seeing how far the persona can stretch and whether it holds up under different conditions.
        This is not about the iterative process on the persona, but my iterative process on the code. I had to rework and restart the code with ChatGPT 6 times before the code actually worked. I had a lot of problems with getting my api key to work, but once I did, on the sixth iteration, I finally got a functioning chatbot. 
Section 4: Conversation Analysis
        The chatbot persona was entirely consistent and distinct in both style and reason throughout every interaction. If you were asking for an explanation, it would provide a concise and step-by-step explanation of said topic. If you were asking it for a methodology, it would incorporate empirical and standardized experiments. If you were asking for a class layout, it would provide you with a minute-by-minute lesson plan and assigned scientific readings. The chatbot was, again, entirely consistent with its assigned persona. Too, the model demonstrated subtle nuanced behaviors, but most center was the follow-up question it would ask at the end of every chat. I thought this was a very crucial feature to the models form, and helped to really emulate what it is like to meet with a professor. Most of the time, your questions are answered with another question. Depth and understanding is key to dedicated scientific inquiry, and I think the model did an exceptional job in demonstrating these characteristics. Lastly, the model never broke down. It was, as aforementioned, consistent and distinct. 
Section 5: Evaluation Framework
        The prompt I used for creating my rubric was the one provided on the github. See it below: 
“You are an expert in AI evaluation metrics and prompt engineering. Help me create a comprehensive scoring rubric for evaluating chatbot persona quality.
CONTEXT:
- Students created persona prompts to make ChatGPT roleplay as specific experts/characters
- We need to score how well a 10-turn conversation reflects the intended persona
- Score should be 0-100 with clear, measurable criteria
PERSONA TO EVALUATE: [INSERT YOUR PERSONA DESCRIPTION HERE]
CONVERSATION: [INSERT YOUR chat_history.md CONTENT HERE]
REQUIREMENTS:
1. Create 4-6 independent evaluation factors
2. Define each factor with specific behavioral indicators
3. Assign weights that sum to 1.0
4. Provide scoring guidelines (what constitutes 90+ vs 60-70 vs <40)
5. Include examples from the conversation for each factor
6. Calculate final weighted score
Make the rubric rigorous enough for academic evaluation but practical for student self-assessment.” I was under the impression that we were to simply use that to create the prompt. However, the rubric it created was exceptional and provided the accurate metrics to fully grade the persona. There were 5 distinct categories, noted above. 
        A key validation concern in applying the rubric is that I didn’t iterate the persona as much as I could have. The chatbot performed strongly across criteria like clarity, domain expertise, etc., so I didn’t refine it further. While this shows the strength of the initial design, it also means the framework wasn’t stress-tested on weaker drafts that might have highlighted limits or inconsistencies. In the future, a more systematic use of the rubric across multiple iterations would strengthen validation by showing not only that the final persona is effective, but also how it improves step by step.
Section 6: Conclusions & Future Work
        To sum up this report, this project demonstrated how thorough persona prompt engineering can create a functional chatbot that adheres to its guidelines, and executes on its roles. I learned that clear organization of the system prompt and a detailed framework leads to success in optimizing a chatbot to adhere to specific instructions/persona. Future work, for me, would include a more extensive prompt iteration process, and fine tuning a persona. I got swept up in creating the bot and appreciating its marvels that I neglected to deviate from the course. I understand the purpose of iteration, and there are a couple of things (insert professor-student interactions, societal context, academic prestige, etc.) that I could expand on. Finally, this project was fascinating and a great first experience in this process.